{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_v02.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RtjShreyD/Eng-Mandarin/blob/master/train_v02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynT4oBwuk5Zt",
        "colab_type": "code",
        "outputId": "d0334cac-001f-4be5-d146-eb4d4071e221",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "!pip install http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch==0.3.0.post4 from http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl in /usr/local/lib/python3.6/dist-packages (0.3.0.post4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from torch==0.3.0.post4) (3.13)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==0.3.0.post4) (1.17.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWObUq1wl5ln",
        "colab_type": "code",
        "outputId": "05f6c5a0-2e36-41f0-b8a7-150b24cb00fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "source": [
        "!pip install torchvision"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.17.4)\n",
            "Collecting torch==1.3.1\n",
            "  Using cached https://files.pythonhosted.org/packages/88/95/90e8c4c31cfc67248bf944ba42029295b77159982f532c5689bcfe4e9108/torch-1.3.1-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (4.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision) (0.46)\n",
            "Installing collected packages: torch\n",
            "  Found existing installation: torch 0.3.0.post4\n",
            "    Uninstalling torch-0.3.0.post4:\n",
            "      Successfully uninstalled torch-0.3.0.post4\n",
            "Successfully installed torch-1.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JY0gZdY9mIMg",
        "colab_type": "code",
        "outputId": "ac58900a-fe37-4721-9bac-aac03b7b2379",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUt3-EP3nOnG",
        "colab_type": "code",
        "outputId": "2b0264c6-6543-410e-88fa-a449e63c5e05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install allennlp"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting allennlp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/bb/041115d8bad1447080e5d1e30097c95e4b66e36074277afce8620a61cee3/allennlp-0.9.0-py3-none-any.whl (7.6MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6MB 8.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.6/dist-packages (from allennlp) (2018.9)\n",
            "Collecting parsimonious>=0.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/fc/067a3f89869a41009e1a7cdfb14725f8ddd246f30f63c645e8ef8a1c56f4/parsimonious-0.8.1.tar.gz (45kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.1MB/s \n",
            "\u001b[?25hCollecting numpydoc>=0.8.0\n",
            "  Downloading https://files.pythonhosted.org/packages/b0/70/4d8c3f9f6783a57ac9cc7a076e5610c0cc4a96af543cafc9247ac307fbfe/numpydoc-0.9.2.tar.gz\n",
            "Collecting jsonpickle\n",
            "  Downloading https://files.pythonhosted.org/packages/07/07/c157520a3ebd166c8c24c6ae0ecae7c3968eb4653ff0e5af369bb82f004d/jsonpickle-1.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: flask>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.1.1)\n",
            "Requirement already satisfied: editdistance in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.5.3)\n",
            "Requirement already satisfied: sqlparse>=0.2.4 in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.3.0)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from allennlp) (3.6.4)\n",
            "Collecting jsonnet>=0.10.0; sys_platform != \"win32\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fe/a6/e69e38f1f259fcf8532d8bd2c4bc88764f42d7b35a41423a7f4b035cc5ce/jsonnet-0.14.0.tar.gz (253kB)\n",
            "\u001b[K     |████████████████████████████████| 256kB 72.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.3.3)\n",
            "Requirement already satisfied: gevent>=1.3.6 in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.4.0)\n",
            "Collecting flask-cors>=3.0.7\n",
            "  Downloading https://files.pythonhosted.org/packages/78/38/e68b11daa5d613e3a91e4bf3da76c94ac9ee0d9cd515af9c1ab80d36f709/Flask_Cors-3.0.8-py2.py3-none-any.whl\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.10.40)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.21.3)\n",
            "Collecting responses>=0.7\n",
            "  Downloading https://files.pythonhosted.org/packages/3e/0c/940781dd49710f4b1f0650c450c9fd8491db0e1bffd99ebc36355607f96d/responses-0.10.9-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tqdm>=4.19 in /usr/local/lib/python3.6/dist-packages (from allennlp) (4.28.1)\n",
            "Collecting overrides\n",
            "  Downloading https://files.pythonhosted.org/packages/ac/98/2430afd204c48ac0a529d439d7e22df8fa603c668d03456b5947cb59ec36/overrides-2.7.0.tar.gz\n",
            "Collecting unidecode\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 48.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from allennlp) (2.8.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.17.4)\n",
            "Collecting tensorboardX>=1.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/5c/e918d9f190baab8d55bad52840d8091dd5114cc99f03eaa6d72d404503cc/tensorboardX-1.9-py2.py3-none-any.whl (190kB)\n",
            "\u001b[K     |████████████████████████████████| 194kB 62.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.18 in /usr/local/lib/python3.6/dist-packages (from allennlp) (2.21.0)\n",
            "Collecting pytorch-transformers==1.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/89/ad0d6bb932d0a51793eaabcf1617a36ff530dc9ab9e38f765a35dc293306/pytorch_transformers-1.1.0-py3-none-any.whl (158kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 59.9MB/s \n",
            "\u001b[?25hCollecting conllu==1.3.1\n",
            "  Downloading https://files.pythonhosted.org/packages/ae/54/b0ae1199f3d01666821b028cd967f7c0ac527ab162af433d3da69242cea2/conllu-1.3.1-py2.py3-none-any.whl\n",
            "Collecting pytorch-pretrained-bert>=0.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 63.8MB/s \n",
            "\u001b[?25hCollecting word2number>=1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/4a/29/a31940c848521f0725f0df6b25dca8917f13a2025b0e8fcbe5d0457e45e6/word2number-1.1.zip\n",
            "Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.6/dist-packages (from allennlp) (3.1.2)\n",
            "Requirement already satisfied: spacy<2.2,>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from allennlp) (2.1.9)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from allennlp) (3.2.5)\n",
            "Collecting flaky\n",
            "  Downloading https://files.pythonhosted.org/packages/fe/12/0f169abf1aa07c7edef4855cca53703d2e6b7ecbded7829588ac7e7e3424/flaky-3.6.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: torch>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.3.1)\n",
            "Collecting ftfy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ca/2d9a5030eaf1bcd925dab392762b9709a7ad4bd486a90599d93cd79cb188/ftfy-5.6.tar.gz (58kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 9.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from parsimonious>=0.8.0->allennlp) (1.12.0)\n",
            "Requirement already satisfied: sphinx>=1.6.5 in /usr/local/lib/python3.6/dist-packages (from numpydoc>=0.8.0->allennlp) (1.8.5)\n",
            "Requirement already satisfied: Jinja2>=2.3 in /usr/local/lib/python3.6/dist-packages (from numpydoc>=0.8.0->allennlp) (2.10.3)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from flask>=1.0.2->allennlp) (7.0)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from flask>=1.0.2->allennlp) (0.16.0)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from flask>=1.0.2->allennlp) (1.1.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (8.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (42.0.2)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (1.8.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (0.7.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (19.3.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (1.3.0)\n",
            "Requirement already satisfied: greenlet>=0.4.14; platform_python_implementation == \"CPython\" in /usr/local/lib/python3.6/dist-packages (from gevent>=1.3.6->allennlp) (0.4.15)\n",
            "Requirement already satisfied: botocore<1.14.0,>=1.13.40 in /usr/local/lib/python3.6/dist-packages (from boto3->allennlp) (1.13.40)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->allennlp) (0.9.4)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->allennlp) (0.2.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->allennlp) (0.14.1)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX>=1.2->allennlp) (3.10.0)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp) (2019.11.28)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 46.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers==1.1.0->allennlp) (2019.12.9)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->allennlp) (2.4.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->allennlp) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->allennlp) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->allennlp) (2.6.1)\n",
            "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1.0->allennlp) (0.9.6)\n",
            "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1.0->allennlp) (2.0.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1.0->allennlp) (0.4.2)\n",
            "Requirement already satisfied: thinc<7.1.0,>=7.0.8 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1.0->allennlp) (7.0.8)\n",
            "Requirement already satisfied: srsly<1.1.0,>=0.0.6 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1.0->allennlp) (0.2.0)\n",
            "Requirement already satisfied: blis<0.3.0,>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1.0->allennlp) (0.2.4)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1.0->allennlp) (2.0.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1.0->allennlp) (1.0.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from ftfy->allennlp) (0.1.7)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (0.7.12)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (2.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (19.2)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (1.1.0)\n",
            "Requirement already satisfied: sphinxcontrib-websupport in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (1.1.2)\n",
            "Requirement already satisfied: babel!=2.0,>=1.3 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (2.7.0)\n",
            "Requirement already satisfied: docutils>=0.11 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (0.15.2)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (2.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.3->numpydoc>=0.8.0->allennlp) (1.1.1)\n",
            "Building wheels for collected packages: parsimonious, numpydoc, jsonnet, overrides, word2number, ftfy\n",
            "  Building wheel for parsimonious (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for parsimonious: filename=parsimonious-0.8.1-cp36-none-any.whl size=42709 sha256=095be23b906984765fa4e04677e9f99ba028c71c5d23b4e4fab7da0e3a9bc5b8\n",
            "  Stored in directory: /root/.cache/pip/wheels/b7/8d/e7/a0e74217da5caeb3c1c7689639b6d28ddbf9985b840bc96a9a\n",
            "  Building wheel for numpydoc (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for numpydoc: filename=numpydoc-0.9.2-cp36-none-any.whl size=31894 sha256=777f71d316f6db8d8402cc68526e9c58593bfcc44a6b1501fee87585b2efe5c1\n",
            "  Stored in directory: /root/.cache/pip/wheels/96/f3/52/25c8e1f40637661d27feebc61dae16b84c7cdd93b8bc3d7486\n",
            "  Building wheel for jsonnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jsonnet: filename=jsonnet-0.14.0-cp36-cp36m-linux_x86_64.whl size=3320310 sha256=0b718d218fd61ec45728ab3cc120616937ca5ad9b930c7a326fadb7710f4fdd5\n",
            "  Stored in directory: /root/.cache/pip/wheels/5b/b7/83/985f0f758fbb34f14989a0fab86d18890d1cc5ae12f26967bc\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for overrides: filename=overrides-2.7.0-cp36-none-any.whl size=5600 sha256=f7cc202cacd07bc8038aa5d83e7a0c03ae2756cab2a2b1918c4c5237ab50e134\n",
            "  Stored in directory: /root/.cache/pip/wheels/8c/7c/ef/80508418b67d87371c5b3de49e03eb22ee7c1d19affb5099f8\n",
            "  Building wheel for word2number (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for word2number: filename=word2number-1.1-cp36-none-any.whl size=5588 sha256=ac357dad6d1288012a66735a810f5f10d95a5573dc0ec0cdb61e31e114b8229e\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/2f/53/5f5c1d275492f2fce1cdab9a9bb12d49286dead829a4078e0e\n",
            "  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ftfy: filename=ftfy-5.6-cp36-none-any.whl size=44553 sha256=5cdde060b513c27c3e7aa83cfc0a185a3ad5f81a4246627e426fe6cabf05f036\n",
            "  Stored in directory: /root/.cache/pip/wheels/43/34/ce/cbb38d71543c408de56f3c5e26ce8ba495a0fa5a28eaaf1046\n",
            "Successfully built parsimonious numpydoc jsonnet overrides word2number ftfy\n",
            "Installing collected packages: parsimonious, numpydoc, jsonpickle, jsonnet, flask-cors, responses, overrides, unidecode, tensorboardX, sentencepiece, pytorch-transformers, conllu, pytorch-pretrained-bert, word2number, flaky, ftfy, allennlp\n",
            "Successfully installed allennlp-0.9.0 conllu-1.3.1 flaky-3.6.1 flask-cors-3.0.8 ftfy-5.6 jsonnet-0.14.0 jsonpickle-1.2 numpydoc-0.9.2 overrides-2.7.0 parsimonious-0.8.1 pytorch-pretrained-bert-0.6.2 pytorch-transformers-1.1.0 responses-0.10.9 sentencepiece-0.1.85 tensorboardX-1.9 unidecode-1.1.1 word2number-1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgOHE81Dn9Ye",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import itertools\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from allennlp.data.dataset_readers.seq2seq import Seq2SeqDatasetReader\n",
        "from allennlp.data.iterators import BucketIterator\n",
        "from allennlp.data.token_indexers import SingleIdTokenIndexer\n",
        "from allennlp.data.tokenizers.character_tokenizer import CharacterTokenizer\n",
        "from allennlp.data.tokenizers.word_tokenizer import WordTokenizer\n",
        "from allennlp.data.vocabulary import Vocabulary\n",
        "from allennlp.nn.activations import Activation\n",
        "from allennlp.models.encoder_decoders.simple_seq2seq import SimpleSeq2Seq\n",
        "from allennlp.modules.attention import LinearAttention, BilinearAttention, DotProductAttention\n",
        "from allennlp.modules.seq2seq_encoders import PytorchSeq2SeqWrapper, StackedSelfAttentionEncoder\n",
        "from allennlp.modules.text_field_embedders import BasicTextFieldEmbedder\n",
        "from allennlp.modules.token_embedders import Embedding\n",
        "from allennlp.predictors import SimpleSeq2SeqPredictor\n",
        "from allennlp.training.trainer import Trainer\n",
        "\n",
        "EN_EMBEDDING_DIM = 256\n",
        "ZH_EMBEDDING_DIM = 256\n",
        "HIDDEN_DIM = 256"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYCa1xsBoHRU",
        "colab_type": "code",
        "outputId": "77143e39-5019-4781-c70a-eaad6424e3c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "reader = Seq2SeqDatasetReader(\n",
        "        source_tokenizer=WordTokenizer(),\n",
        "        target_tokenizer=CharacterTokenizer(),\n",
        "        source_token_indexers={'tokens': SingleIdTokenIndexer()},\n",
        "        target_token_indexers={'tokens': SingleIdTokenIndexer(namespace='target_tokens')})\n",
        "    \n",
        "train_dataset = reader.read('/content/drive/My Drive/Eng_Mandarin/data/tatoeba.eng_cmn.train.tsv')\n",
        "validation_dataset = reader.read('/content/drive/My Drive/Eng_Mandarin/data/tatoeba.eng_cmn.dev.tsv')\n",
        "\n",
        "vocab = Vocabulary.from_instances(train_dataset + validation_dataset, \n",
        "                                  min_count={'tokens': 3, 'target_tokens': 3})\n",
        "\n",
        "en_embedding = Embedding(num_embeddings=vocab.get_vocab_size('tokens'), \n",
        "                         embedding_dim=EN_EMBEDDING_DIM)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "37400it [00:14, 2607.59it/s]\n",
            "4676it [00:01, 2699.48it/s]\n",
            "100%|██████████| 42076/42076 [00:00<00:00, 72356.80it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFH_fNYoovEs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder = StackedSelfAttentionEncoder(\n",
        "        input_dim=EN_EMBEDDING_DIM, \n",
        "        hidden_dim=HIDDEN_DIM, \n",
        "        projection_dim=128, \n",
        "        feedforward_hidden_dim=128, \n",
        "        num_layers=1, \n",
        "        num_attention_heads=8)\n",
        "\n",
        "source_embedder = BasicTextFieldEmbedder({\"tokens\": en_embedding})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NI3LoWe7pVMe",
        "colab_type": "code",
        "outputId": "f9cde065-f934-4377-9678-e5a1eba7d763",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "attention = DotProductAttention()\n",
        "\n",
        "max_decoding_steps = 20 \n",
        "\n",
        "model = SimpleSeq2Seq(vocab, source_embedder, encoder, max_decoding_steps,\n",
        "                      target_embedding_dim=ZH_EMBEDDING_DIM,\n",
        "                      target_namespace='target_tokens',\n",
        "                      attention=attention,\n",
        "                      beam_size=8,\n",
        "                      use_bleu=True)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  CUDA_DEVICE = 0\n",
        "  model = model.cuda(CUDA_DEVICE)\n",
        "  print(\"Model deployed on GPU\")\n",
        "else:\n",
        "  CUDA_DEVICE = -1\n",
        "  print(\"Model deployed on CPU\")\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "iterator = BucketIterator(batch_size=32, sorting_keys=[(\"source_tokens\", \"num_tokens\")])\n",
        "\n",
        "iterator.index_with(vocab)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model deployed on GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKHswE5opxCI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainer = Trainer(model=model, \n",
        "                  optimizer=optimizer,\n",
        "                  iterator=iterator,\n",
        "                  train_dataset=train_dataset,\n",
        "                  validation_dataset=validation_dataset,\n",
        "                  num_epochs=50,\n",
        "                  patience=1,\n",
        "                  cuda_device=CUDA_DEVICE)\n",
        "                     \n",
        "trainer.train()\n",
        "predictor = SimpleSeq2SeqPredictor(model, reader)\n",
        "\n",
        "for instance in itertools.islice(validation_dataset, 10):\n",
        "  print('SOURCE:', instance.fields['source_tokens'].tokens)\n",
        "  print('GOLD:', instance.fields['target_tokens'].tokens)\n",
        "  print('PRED:', predictor.predict_instance(instance)['predicted_tokens'])\n",
        "  print('////////////////////////////////////////////\\n')\n",
        "\n",
        "with open(\"/content/drive/My Drive/Eng_Mandarin/data/model.th\", 'wb') as f:\n",
        "  torch.save(model.state_dict(), f)\n",
        "vocab.save_to_files(\"/content/drive/My Drive/Eng_Mandarin/data/vocabulary\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnXuAOBUOdbC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        },
        "outputId": "753fa7c3-1964-458f-e227-8cf7fdbda484"
      },
      "source": [
        "vocab2 = Vocabulary.from_files(\"/content/drive/My Drive/Eng_Mandarin/data/vocabulary\")\n",
        "model2 = SimpleSeq2Seq(vocab2, source_embedder, encoder, max_decoding_steps,\n",
        "                      target_embedding_dim=ZH_EMBEDDING_DIM,\n",
        "                      target_namespace='target_tokens',\n",
        "                      attention=attention,\n",
        "                      beam_size=8,\n",
        "                      use_bleu=True)\n",
        "\n",
        "with open(\"/content/drive/My Drive/Eng_Mandarin/data/model.th\", 'rb') as f:\n",
        "  model2.load_state_dict(torch.load(f))\n",
        "\n",
        "if CUDA_DEVICE > -1:\n",
        "    model2.cuda(CUDA_DEVICE)\n",
        "\n",
        "predictor2 = SimpleSeq2SeqPredictor(model2, reader)\n",
        "\n",
        "for instance in itertools.islice(validation_dataset, 10):\n",
        "  print('SOURCE:', instance.fields['source_tokens'].tokens)\n",
        "  print('GOLD:', instance.fields['target_tokens'].tokens)\n",
        "  print('PRED:', predictor2.predict_instance(instance)['predicted_tokens'])\n",
        "  print('////////////////////////////////////////////\\n')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SOURCE: [@start@, I, have, to, go, to, sleep, ., @end@]\n",
            "GOLD: [@start@, 我, 该, 去, 睡, 觉, 了, 。, @end@]\n",
            "PRED: ['我', '必', '睡', '睡', '觉', '。', '。']\n",
            "////////////////////////////////////////////\n",
            "\n",
            "SOURCE: [@start@, I, just, do, n't, know, what, to, say, ., @end@]\n",
            "GOLD: [@start@, 我, 就, 是, 不, 知, 道, 說, 些, 什, 麼, 。, @end@]\n",
            "PRED: ['我', '不', '知', '不', '知', '道', '的', '的', '什', '麼', '。']\n",
            "////////////////////////////////////////////\n",
            "\n",
            "SOURCE: [@start@, I, may, give, up, soon, and, just, nap, instead, ., @end@]\n",
            "GOLD: [@start@, 也, 许, 我, 会, 马, 上, 放, 弃, 然, 后, 去, 睡, 一, 觉, 。, @end@]\n",
            "PRED: ['我', '许', '我', '很', '开', '上', '去', '松', '。', '后', '。', '。', '觉', '步', '。']\n",
            "////////////////////////////////////////////\n",
            "\n",
            "SOURCE: [@start@, I, 'm, going, to, go, ., @end@]\n",
            "GOLD: [@start@, 我, 要, 走, 了, 。, @end@]\n",
            "PRED: ['我', '要', '去', '了', '。']\n",
            "////////////////////////////////////////////\n",
            "\n",
            "SOURCE: [@start@, That, 's, MY, line, !, @end@]\n",
            "GOLD: [@start@, 那, 是, 我, 的, 台, 词, ！, @end@]\n",
            "PRED: ['那', '是', '一', '的', '一', '@@UNKNOWN@@', '！']\n",
            "////////////////////////////////////////////\n",
            "\n",
            "SOURCE: [@start@, It, does, n't, surprise, me, ., @end@]\n",
            "GOLD: [@start@, 这, 并, 不, 让, 我, 惊, 讶, 。, @end@]\n",
            "PRED: ['不', '不', '不', '是', '我', '。', '讶', '。']\n",
            "////////////////////////////////////////////\n",
            "\n",
            "SOURCE: [@start@, I, 'm, not, a, real, fish, ,, I, 'm, just, a, mere, plushy, ., @end@]\n",
            "GOLD: [@start@, 我, 不, 是, 一, 条, 真, 的, 鱼, ，, 我, 只, 是, 一, 个, 长, 毛, 绒, 玩, 具, 。, @end@]\n",
            "PRED: ['我', '不', '吃', '吃', '個', '狗', '的', '，', '，', '但', '也', '是', '个', '个', '大', '蛋', '蒜', '。', '。', '。']\n",
            "////////////////////////////////////////////\n",
            "\n",
            "SOURCE: [@start@, I, thought, you, liked, to, learn, new, things, ., @end@]\n",
            "GOLD: [@start@, 我, 以, 為, 你, 喜, 歡, 學, 習, 新, 事, 物, 。, @end@]\n",
            "PRED: ['我', '想', '为', '你', '應', '歡', '這', '校', '。', '的', '。', '。']\n",
            "////////////////////////////////////////////\n",
            "\n",
            "SOURCE: [@start@, This, is, not, important, ., @end@]\n",
            "GOLD: [@start@, 這, 個, 不, 重, 要, 。, @end@]\n",
            "PRED: ['这', '不', '不', '重', '要', '。']\n",
            "////////////////////////////////////////////\n",
            "\n",
            "SOURCE: [@start@, Thanks, for, having, explained, to, me, at, last, why, people, take, me, for, an, idiot, ., @end@]\n",
            "GOLD: [@start@, 感, 谢, 最, 后, 为, 我, 说, 明, 了, 为, 什, 么, 人, 们, 把, 我, 当, 作, 傻, 瓜, 了, 。, @end@]\n",
            "PRED: ['谢', '谢', '你', '好', '，', '我', '是', '谎', '白', '一', '人', '么', '。', '。', '。', '我', '的', '然', '家', '子', '。', '。']\n",
            "////////////////////////////////////////////\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxVxqRXfOk1B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}